{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67044b0",
   "metadata": {},
   "source": [
    "# Prédiction de la consommation d'électricité en France :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e03299",
   "metadata": {},
   "source": [
    "Projet developpement logiciel \n",
    "\n",
    "Traîtement des données sur Jupyter Notebook (distribution Anaconda) \n",
    "\n",
    "Etude réalisée en language Python \n",
    "\n",
    "Source des données : [Données annuelles de la consommation brute d'électricité du 1er Janvier 2012 au 31 mai 2022](https://www.data.gouv.fr/fr/datasets/pic-journalier-de-la-consommation-brute-delectricite-janvier-2012-a-septembre-2022/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01df5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les librairies nécessaires:\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interact, interactive, fixed, interact_manual\n",
    "import statsmodels.api as sm\n",
    "import pooch\n",
    "from IPython import get_ipython\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "import pmdarima  ## utilisé pour l'application de la fonction auto_arima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "from statsmodels.tsa.seasonal import (\n",
    "    seasonal_decompose,\n",
    ")  # décomposer la série temporelle\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import (\n",
    "    adfuller,\n",
    ")  # tester  la stationnarité de la série temporelle\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pylab\n",
    "from pylab import rcParams  # paramètres de style\n",
    "import statsmodels.api as sm\n",
    "import warnings  # pour se débarasser des warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "register_matplotlib_converters()\n",
    "color_pal = sns.color_palette()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6398c36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas : 1.4.4\n",
      "Numpy : 1.23.3\n",
      "Matplotlib : 3.5.2\n",
      "Seaborn : 0.11.2\n",
      "Statsmodels : 0.13.5\n"
     ]
    }
   ],
   "source": [
    "# Versions utilisées :\n",
    "print(\"Pandas : \" + str(pd.__version__))\n",
    "print(\"Numpy : \" + str(np.__version__))\n",
    "print(\"Matplotlib : \" + str(matplotlib.__version__))\n",
    "print(\"Seaborn : \" + str(sns.__version__))\n",
    "print(\"Statsmodels : \" + str(sm.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0342ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètre de style :\n",
    "pylab.style.use(\"fivethirtyeight\")\n",
    "params = {\n",
    "    \"legend.fontsize\": \"x-large\",\n",
    "    \"figure.figsize\": (20, 6),\n",
    "    \"lines.linewidth\": 1.8,\n",
    "    \"axes.labelsize\": \"x-large\",\n",
    "    \"axes.titleweight\": \"bold\",\n",
    "    \"xtick.labelsize\": \"x-large\",\n",
    "    \"ytick.labelsize\": \"x-large\",\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66274b02",
   "metadata": {},
   "source": [
    "## 1- Création de la base de données :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a8562",
   "metadata": {},
   "source": [
    "### 1.1 - Téléchargement des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73221727",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://www.data.gouv.fr/fr/datasets/r/72c72414-a2d8-4dc5-b699-ff70eb6b4c4c' to file 'C:\\Users\\thiba\\OneDrive\\Bureau\\Projet\\hax712x_project\\trackelec\\predic\\consommation.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Création du fichier 'consommation.csv' à partit de l'url\n",
    "\n",
    "url = \"https://www.data.gouv.fr/fr/datasets/r/72c72414-a2d8-4dc5-b699-ff70eb6b4c4c\"\n",
    "path_target = \"./consommation.csv\"\n",
    "path, fname = os.path.split(path_target)\n",
    "pooch.retrieve(url, path=path, fname=fname, known_hash=None)\n",
    "\n",
    "# Chargement du dataset \"consommation.csv\"\n",
    "data = pd.read_csv(\n",
    "    \"consommation.csv\",\n",
    "    delimiter=\";\",\n",
    "    comment=\"#\",\n",
    "    na_values=\"n/d\",\n",
    "    parse_dates=[\"date\"],\n",
    "    converters={\"heure\": str},\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df4f7e",
   "metadata": {},
   "source": [
    "### 1.2 - Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da55da7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Restriction des données sur les modalités \"date\", heure\" et \"consommation\"\n",
    "\n",
    "df = data.copy()\n",
    "df = data[[\"date\", \"heure\", \"consommation\"]]\n",
    "df = df.rename(\n",
    "    columns={\"date\": \"Date\", \"heure\": \"Heure\", \"consommation\": \"Consommation\"}\n",
    ")\n",
    "df = df.dropna(axis=0)  # supprimer les valeurs manquantes\n",
    "df = df.set_index(\"Date\")\n",
    "df.index = pd.to_datetime(df.index)  # convertir l'objet 'Datetime' de string à datetime\n",
    "df = df.sort_values(\n",
    "    by=[\"Date\", \"Heure\"], ascending=(True, True)\n",
    ")  # trier le dataframe dans l'ordre croissant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7c81c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# description des données\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440a7ed",
   "metadata": {},
   "source": [
    "### 1.3 Aperçu des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd17d91",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualisation des données :\n",
    "df.plot()\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Consommation\")\n",
    "plt.title(\"Consommation d'électricité en France (MW)\")\n",
    "plt.show()\n",
    "# plt.savefig(\"Consommation_elec.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16ca1e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6d90f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304643d8",
   "metadata": {},
   "source": [
    "# 2- Principe du modèle ARIMA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb6d47",
   "metadata": {},
   "source": [
    "## Qu'est ce qu'une série temporelle? \n",
    "\n",
    "une série temporelle est une suite finie $(x_1, ..., x_n)$ de données indexée par le temps, l'indice de temps peut être le jour, l'année etc, le nombre $n$ est appelé la longueur de la série.\n",
    "\n",
    "Une série temporelle peur être décomposée en 3 composantes:\n",
    "\n",
    "1. Tendance : \n",
    "elle montre une direction générale des données de la série chronologique sur une longue période. Une tendance peut être croissante , décroissante ou horizontale (stationnaire).\n",
    "\n",
    "2. Saisonnalité : \n",
    "la composante saisonnière présente une tendance qui se répète en ce qui concerne le moment, la direction et l’ampleur, le chocolat par exemple est un produit saisonnier connaîssant de fortes ventes durant Pâcques , Noël et une réduction de ventes durant l'été.\n",
    "\n",
    "3. Bruit :\n",
    "qui représente des pics et des creux à intervalles aléatoires.\n",
    "\n",
    "### Qu'est ce qu'une série stationnaire?\n",
    "\n",
    "Une série est stationnaire si :\n",
    "\n",
    "1. La moyenne et la variance de la série ne varient pas dans le temps .\n",
    "\n",
    "2. La covariance du i-ème terme et du (i+m) -ième terme n'est fonction du temps.\n",
    "\n",
    "\n",
    "\n",
    "### Pourquoi avoir choisi le modèle ARIMA??\n",
    "\n",
    "ARIMA est un modèle statistique conçu pour l'analyse et la prédiction des données d'une série temporelle , il permet de déterminer les valeurs intégrées à cette dernière en fonction des précédentes observations , c'est pour cette raison que nous avons choisi ce modèle pour notre projet.\n",
    "\n",
    "\n",
    "### Paramètres du modèle :\n",
    "\n",
    "Le modèle ARIMA possède 3 paramètres :p, d et q , il s'écrit de la manière suivante : ARIMA(p, d , q) où:\n",
    "\n",
    "p : le nombre de décalage qu'il faudra considérer pour le modèle autoregressif .\n",
    "\n",
    "d : le nombre de fois qu'il faut différentier la série afin de la rendre stationnaire (vous verrez ci-dessus que d=0 car notre processus est déjà stationnaire).\n",
    "\n",
    "q : l'ordre du modèle MA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68924d",
   "metadata": {},
   "source": [
    "## 2.1 - Aggrégation des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed483cb2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de95584",
   "metadata": {},
   "source": [
    "Nous allons Aggréger les données en prenant la moyenne de la consommation d'électricité par jour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefc1ed",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    weekly_cons = df1.groupby([\"Consommation\", pd.Grouper(key=\"Date\", freq=\"D\")]).size()\n",
    "    weekly_cons = weekly_cons.unstack(0)\n",
    "except:\n",
    "    print(\"\\n Here seems to be one issue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e1c46",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df1 = df[[\"Consommation\"]].resample(\"D\").mean()\n",
    "df1 = pd.DataFrame(df1)  # convertir l'objet ts en dataframe\n",
    "df1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34f7f4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf7540",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(df1)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Consommation (MW)\")\n",
    "plt.title(\"Moyenne de la consommation d'électricité par jour\")\n",
    "plt.show()\n",
    "# plt.savefig(\"conso_hebdo.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e640eef",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decomp = sm.tsa.seasonal_decompose(df1, model=\"additive\")\n",
    "fig = decomp.plot()\n",
    "plt.show()\n",
    "# plt.savefig(\"decomp.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce4a2c",
   "metadata": {},
   "source": [
    "## Test de vérification de la stationnalité de la série temporelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d8607d",
   "metadata": {},
   "source": [
    "Afin de tester la stationnalité de la série , nous avons deux méthodes :\n",
    "\n",
    "1. À l'oeil nu en traçant la moyenne et l'écart type mobile . \n",
    "\n",
    "2. En appliquant le test de Dickey-Fuller (nous verrons que c'est une méthode qui prends du temps..)\n",
    "\n",
    "Si la valeur du paramètre p est inférieure ou égale à 0.05 alors d=0 et notre série est stationnaire (nous rejetons l'hypothèse nulle sinon elle ne l'est pas . \n",
    "\n",
    "\n",
    "À partir du package statsmodels, la fonction de test dickey-fuller augmentée est importée. Il renvoie un tuple composé des valeurs : adf, pvalue, usedlag, nobs, critical values etc\n",
    "\n",
    "Nous allons commencer par définir une fonction qui nous permet d'effectuer tous ces tests :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4e1db",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_stationarity(timeseries):\n",
    "    # Statistiques mobiles\n",
    "    rolling_mean = timeseries.rolling(window=12).mean()\n",
    "    rolling_std = timeseries.rolling(window=12).std()\n",
    "\n",
    "    # tracé statistiques mobiles\n",
    "    original = plt.plot(timeseries, color=\"blue\", label=\"Données originales\")\n",
    "    mean = plt.plot(rolling_mean, color=\"red\", label=\"Moyenne Mobile\")\n",
    "    std = plt.plot(rolling_std, color=\"green\", label=\"Ecart-type Mobile\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Moyenne et écart-type Mobiles\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "    # Test Dickey–Fuller :\n",
    "    res = adfuller(timeseries[\"Consommation\"])\n",
    "    print(\"Statistiques ADF : {}\".format(res[0]))\n",
    "    print(\"p-value : {}\".format(res[1]))\n",
    "    print(\"Valeurs Critiques :\")\n",
    "    for key, value in res[4].items():\n",
    "        print(\"\\t{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64261e1d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Déf d'une fonction qui teste la valeur de p:\n",
    "def test_val_p(data):\n",
    "    fuller_test = adfuller(data)\n",
    "    print(\"La valeur de p est:\", fuller_test[1])\n",
    "    if fuller_test[1] <= 0.05:\n",
    "        print(\"la série est stationaire\")\n",
    "    else:\n",
    "        print(\"la série n'est pas stationaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d694f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "get_stationarity(df1)\n",
    "plt.savefig(\"moy_ecart_type.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb4345",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_val_p(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaa690",
   "metadata": {},
   "source": [
    " ## Construction du modèle ARIMA:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae845045",
   "metadata": {},
   "source": [
    "### Comment obtenir les valeurs de p, d ,q : nous allons utiliser la fonction auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae72985",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pip install pmdarima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b8788",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Nous voulons connaître le nombre de combinaisons possibles entre p, d et q:\n",
    "p = range(0, 8)\n",
    "d = range(0, 8)\n",
    "q = range(0, 2)\n",
    "\n",
    "pdq_comb = list(itertools.product(p, d, q))\n",
    "len(pdq_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c18fc1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Création et test du modèle:\n",
    "train = df1.loc[df1.index < \"2020-12-08\"]\n",
    "test = df1.loc[df1.index >= \"2020-12-08\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef425d5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30657711",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualisation train/test split :\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "train.plot(ax=ax, label=\"Training Set\", title=\"Data Train/Test Split\")\n",
    "test.plot(ax=ax, label=\"Test Set\")\n",
    "ax.axvline(\"2020-12-08\", color=\"green\", ls=\"--\")\n",
    "ax.legend([\"Modèle\", \"Test\"])\n",
    "plt.show()\n",
    "# plt.savefig(\"data_train_tes.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5b241",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(2,1,1)(2,0,1)[12] intercept   : AIC=62147.813, Time=22.90 sec\n",
      " ARIMA(2,1,1)(2,0,0)[12] intercept   : AIC=62196.598, Time=16.89 sec\n",
      " ARIMA(2,1,1)(2,0,2)[12] intercept   : AIC=inf, Time=34.63 sec\n",
      " ARIMA(2,1,1)(1,0,2)[12] intercept   : AIC=inf, Time=19.45 sec\n",
      " ARIMA(1,1,1)(2,0,1)[12] intercept   : AIC=62485.417, Time=7.41 sec\n",
      " ARIMA(2,1,0)(2,0,1)[12] intercept   : AIC=62373.094, Time=8.01 sec\n",
      " ARIMA(3,1,1)(2,0,1)[12] intercept   : AIC=62115.382, Time=13.73 sec\n",
      " ARIMA(3,1,1)(1,0,1)[12] intercept   : AIC=62113.418, Time=3.01 sec\n",
      " ARIMA(3,1,1)(0,0,1)[12] intercept   : AIC=62127.121, Time=2.30 sec\n",
      " ARIMA(3,1,1)(1,0,0)[12] intercept   : AIC=62111.590, Time=2.40 sec\n",
      " ARIMA(3,1,1)(0,0,0)[12] intercept   : AIC=62448.299, Time=1.29 sec\n",
      " ARIMA(3,1,1)(2,0,0)[12] intercept   : AIC=62113.438, Time=7.48 sec\n",
      " ARIMA(3,1,0)(1,0,0)[12] intercept   : AIC=62415.145, Time=1.62 sec\n",
      " ARIMA(4,1,1)(1,0,0)[12] intercept   : AIC=61947.918, Time=3.17 sec\n",
      " ARIMA(4,1,1)(0,0,0)[12] intercept   : AIC=62131.326, Time=0.92 sec\n",
      " ARIMA(4,1,1)(2,0,0)[12] intercept   : AIC=61943.954, Time=10.14 sec\n",
      " ARIMA(4,1,1)(2,0,1)[12] intercept   : AIC=61945.736, Time=16.69 sec\n",
      " ARIMA(4,1,1)(1,0,1)[12] intercept   : AIC=61944.255, Time=4.02 sec\n",
      " ARIMA(4,1,0)(2,0,0)[12] intercept   : AIC=62065.646, Time=6.92 sec\n",
      " ARIMA(5,1,1)(2,0,0)[12] intercept   : AIC=61635.853, Time=9.15 sec\n",
      " ARIMA(5,1,1)(1,0,0)[12] intercept   : AIC=61639.288, Time=3.46 sec\n",
      " ARIMA(5,1,1)(2,0,1)[12] intercept   : AIC=61621.760, Time=26.08 sec\n",
      " ARIMA(5,1,1)(1,0,1)[12] intercept   : AIC=61641.497, Time=5.60 sec\n",
      " ARIMA(5,1,1)(2,0,2)[12] intercept   : AIC=inf, Time=38.65 sec\n",
      " ARIMA(5,1,1)(1,0,2)[12] intercept   : AIC=61621.790, Time=22.38 sec\n",
      " ARIMA(5,1,0)(2,0,1)[12] intercept   : AIC=61631.152, Time=19.84 sec\n",
      " ARIMA(5,1,2)(2,0,1)[12] intercept   : AIC=60681.263, Time=38.41 sec\n",
      " ARIMA(5,1,2)(1,0,1)[12] intercept   : AIC=60679.034, Time=15.13 sec\n",
      " ARIMA(5,1,2)(0,0,1)[12] intercept   : AIC=60686.153, Time=10.71 sec\n",
      " ARIMA(5,1,2)(1,0,0)[12] intercept   : AIC=60707.512, Time=12.30 sec\n"
     ]
    }
   ],
   "source": [
    "import pmdarima\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "auto_arima(\n",
    "    train,\n",
    "    m=12,\n",
    "    start_P=0,\n",
    "    seasonal=True,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    stepwise=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df86767a",
   "metadata": {},
   "source": [
    "# 3- Application du modèle ARIMA au données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4c053",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df1)\n",
    "model = ARIMA(df1, order=(5, 1, 3), seasonal_order=(0, 0, 2, 12))\n",
    "results = model.fit()\n",
    "plt.plot(df1)\n",
    "plt.plot(results.fittedvalues, color=\"red\")\n",
    "plt.title(\"Prédiction sur les données\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a357c",
   "metadata": {},
   "source": [
    "## Application du modèle au test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc7408",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df1)\n",
    "model = ARIMA(test, order=(5, 1, 3), seasonal_order=(0, 0, 2, 12))\n",
    "results = model.fit()\n",
    "plt.plot(df1)\n",
    "plt.plot(results.fittedvalues, color=\"red\")\n",
    "plt.title(\"Prédiction sur le test\")\n",
    "plt.legend([\"Vrai données\", \"Prédictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fb5f7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c29986",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# prédiction du 2022-06-01 jusqu'au 2022-12-08 : 192 jours\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "new_dates = [df1.index[-1] + DateOffset(days=x) for x in range(1, 192)]\n",
    "df1_pred = pd.DataFrame(index=new_dates, columns=df1.columns)\n",
    "df1_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b452b01",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5f6e1",
   "metadata": {},
   "source": [
    "Le modèle ARIMA prend comme arguments le début et la fin de l'index énuméré et non la plage de dates.\n",
    "\n",
    "Nous avons créé un datframe vide ayant des index de dates futures et nous allons les concaténer avec notre dataframe d'origine.\n",
    "\n",
    "Notre dataframe avait 3804 lignes et le nouveau possède 199 lignes, on a au total 4004 lignes.\n",
    "\n",
    "Par conséquent, pour obtenir les prédictions uniquement pour les données futures, nous allons prédire de la ligne 3805 à 4004 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f6654",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([df1, df1_pred])\n",
    "\n",
    "df2[\"predictions\"] = results.predict(start=3805, end=4004)\n",
    "df2[[\"Consommation\", \"predictions\"]].plot()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24f862",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len(df1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc8380",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb1140",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results.resid.plot()\n",
    "plt.title(\"Résidus de la prédiction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c6d4f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "results.resid.plot(kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f256a87",
   "metadata": {},
   "source": [
    "Cette méthode n'a pas vraiment abouti à grand chose , après plusieurs recherches , nous avons trouvé un outil très puissant nommé \"prophet\" à partir duquel nous allons nous appuyer dans la suite de notre raisonnement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c2a15d",
   "metadata": {},
   "source": [
    "## Autre méthode : utiliser le package prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb91911",
   "metadata": {},
   "source": [
    "Prophet est un package qui permet d'effectuer des prévisions des données de séries temporelles basées sur un modèle additif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6372ac0",
   "metadata": {},
   "source": [
    "Nous allons à présent travailler avec [les données de la consommation d'électricité en France du 01 Juin 2022 jusqu'au 29 novembre 2022](https://odre.opendatasoft.com/explore/dataset/eco2mix-national-tr/download/?format=csv&disjunctive.nature=true&q=date_heure:%5B2022-05-31T22:00:00Z+TO+2022-11-29T22:59:59Z%5D&timezone=Europe/Berlin&lang=fr&use_labels_for_header=true&csv_separator=%3B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4b8c4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Téléchargement des données de 2022:\n",
    "url2 = \"https://odre.opendatasoft.com/explore/dataset/eco2mix-national-tr/download/?format=csv&disjunctive.nature=true&q=date_heure:%5B2022-05-31T22:00:00Z+TO+2022-11-29T22:59:59Z%5D&timezone=Europe/Berlin&lang=fr&use_labels_for_header=true&csv_separator=%3B\"\n",
    "path_target = \"./consommation_2022.csv\"\n",
    "path, fname = os.path.split(path_target)\n",
    "pooch.retrieve(url2, path=path, fname=fname, known_hash=None)\n",
    "\n",
    "# Chargement du dataset \"consommation.csv\"\n",
    "data1 = pd.read_csv(\n",
    "    \"consommation_2022.csv\",\n",
    "    delimiter=\";\",\n",
    "    comment=\"#\",\n",
    "    na_values=\"n/d\",\n",
    "    parse_dates=[\"Date\"],\n",
    "    converters={\"heure\": str},\n",
    ")\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d79e95",
   "metadata": {},
   "source": [
    "Afin d'appliquer prophet , notre adataframe doit avoir une forme spécifique :\n",
    "\n",
    "la première colonne doit porter le nom 'ds' et contenir les dates et la deuxième colonne doit porter le nom de 'y' et contenir ce que l'on veut prédire , dans notre cas 'consommation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b162ca9",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Restriction des données sur les modalités \"date \" ,\" heure\" et \"consommation\"\n",
    "df2 = data1.copy()\n",
    "df2 = data1[[\"Date\", \"Heure\", \"Consommation (MW)\"]]\n",
    "df2 = df2.rename(columns={\"Date\": \"ds\", \"Consommation (MW)\": \"y\"})\n",
    "df2 = df2.dropna()  # supprimer les valeurs aberrantes\n",
    "df2 = df2.sort_values(\n",
    "    by=[\"ds\", \"Heure\"], ascending=(True, True)\n",
    ")  # ordonner les colonnes 'ds' et 'Heure' dans l'ordre croissant\n",
    "df2[\"ds\"] = pd.to_datetime(df2[\"ds\"])  # convertir l'objet 'ds' en datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63985c22",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad757787",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df2.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30d575",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Test du modèle :\n",
    "model = Prophet()\n",
    "model.fit(df2)\n",
    "future = model.make_future_dataframe(periods=10, freq=\"15min\", include_history=False)\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfbfb1",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d7e17",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "forecast[[\"ds\", \"yhat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f09c7",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Prédiction sur 10 jours à partir du 29 novembre :\n",
    "m = Prophet()\n",
    "m.fit(df2)  # ajuster notre modèle 'm' sur l'ensemble des données\n",
    "f = model.make_future_dataframe(periods=96 * 10, freq=\"15min\", include_history=False)\n",
    "predic = model.predict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5acaf4d",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "s = predic[[\"ds\", \"yhat\"]]  # la colonne 'yhat' contient les prédiction\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b78c99",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predic_finale = s[len(s) - 97 : 959]\n",
    "predic_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec6035",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predic_finale = predic_finale.rename(\n",
    "    columns={\"ds\": \"Date et Heure\", \"yhat\": \"Consommation (MW)\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f335b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "predic_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1c69b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(predic_finale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26194a",
   "metadata": {},
   "source": [
    "### Création du dataframe 'prediction.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938ec95",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv(path_or_buf=\"./prediction.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9aee26b8537bbcf9ce043f2f6dc7b778f5587084830d060111226e3928758449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
